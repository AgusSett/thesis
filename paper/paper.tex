\documentclass[]{report}
\usepackage[a4paper]{geometry}
\usepackage[spanish]{babel}
\usepackage{hyperref}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{ebproof}
\usepackage{float}
\usepackage[conor]{agda}
\usepackage{fancyhdr}
\pagestyle{fancy}
\usepackage[style=alphabetic]{biblatex}
\addbibresource{references.bib}
\usepackage{tikz}
\usetikzlibrary{decorations.pathreplacing,calc,tikzmark,calligraphy}
\usetikzlibrary{arrows.meta,positioning,matrix}
\setlength{\headheight}{13.07225pt}

%opening
\title{Formalización de Sistema I con tipo Top}
\author{Agustin Settimo}

\begin{document}
	
	\maketitle
	\tableofcontents
	
	\begin{abstract}
		
	\end{abstract}
	
	\chapter{Introducción}
	Los sistemas de tipos permiten especificar el comportamiento de los programas.
	Por ejemplo, el tipo $(A \times B) \rightarrow C$ representa los programas que permiten obtener un valor de tipo $C$ a partir de un par de valores de tipo $A$ y $B$.
	Por otro lado, el tipo $A \rightarrow B \rightarrow C$ representa los programas que primero acepta un valor de tipo $A$, luego uno de tipo $B$ y finalmente devuelve un valor de tipo $C$.
	Estas dos especificaciones son distintas en su forma pero parecen tener el mismo significado semántico. Esto se debe al isomorfismo de Curry.
	Debido a la estrecha relación entre la programación y la lógica, se observa un comportamiento análogo cuando se trabaja con pruebas.
	Por ejemplo, una prueba de $(A \wedge B) \Rightarrow C$ no constituye una prueba de $A \Rightarrow B \Rightarrow C$, y viceversa, a pesar de que ambas tienen el mismo significado.
	
	\section{Motivación}
	
	Tanto los sistemas de tipos como los sistemas de pruebas distinguen elementos que tienen diferente forma aunque tengan el mismo significado, como pueden ser las pruebas de las conjunciones $A \wedge B$ y $B \wedge A$, por lo cual una prueba de una no constituye una prueba de la otra, a pesar de que se puede demostrar mediante la existencia de un isomorfismo que dichas proposiciones son equivalentes.
	
	Programas con tipos isomorfos representan el mismo tipo de problema, por lo que tratarlos como si fueran idénticos tiene aplicaciones interesantes.
	Desde el punto de vista de los programas, nos permite construir expresiones que antes no eran posibles, por ejemplo, un término $f : (A \times B) \rightarrow C$ puede ser combinado como $f \langle a, b \rangle$ ó $f \: a \: b$, es decir, es posible evadir cierta rigidez impuesta por el sistema de tipos.
	Por otro lado, los isomorfismos hacen que las pruebas sean más naturales, por ejemplo, para probar, $A \wedge (A \Rightarrow  B) \Rightarrow B$, deberíamos primero introducir la hipótesis $A \wedge A \Rightarrow  B$, y luego descomponerla en $A$ y $A \Rightarrow B$, en cambio, utilizando el isomorfismo de curry transformamos el objetivo en $(A \Rightarrow A \Rightarrow  B) \Rightarrow B$ y luego introducimos directamente las hipótesis $A$ y $A \Rightarrow B$.
	
	\section{Estado del arte}
	\subsection{Isomorfismos de tipos}
	
	Para poder abstraernos de la forma y centrarnos en el significado de los programas, es necesario establecer cuáles son las formas que son combinables y cómo combinarlas.
	Para ello nos valdremos de la noción de isomorfismo entre tipos.
	El primer paso es considerar dos proposiciones $A$ y $B$ como isomorfas si existen dos pruebas $A \Rightarrow B$ y $B \Rightarrow A$, tal que al componerlas, en ambos sentidos, obtenemos como resultado la identidad.
	Por ejemplo, para probar que $A \Rightarrow (B \times C) \equiv (A \Rightarrow B) \times (A \Rightarrow C)$ es efectivamente un isomorfismo, se define un término $curry$ que dada una función devuelve su forma currificada, y un término $uncurry$ que realiza la operación inversa:
	
	\[ curry = \lambda x^{(A \times B) \Rightarrow C}. \lambda a^A . \lambda b^B . x\langle a,b \rangle \]
	\[ uncurry = \lambda x^{A \Rightarrow B \Rightarrow C}. \lambda y^{A \times B} . x(\pi_1 y)(\pi_2 y) \]
	
	Luego, se demuestra por extensionalidad que para cualquier par $\langle u,v \rangle$ y función $f$ se cumple $uncurry \circ curry = id_{(A \times B) \Rightarrow C}$:
	
	\begin{align*}
		 & (uncurry \circ curry) f \langle u,v \rangle \\
		=& \\
		 & uncurry (curry \; f) \langle u,v \rangle \\
		=& \\
		 & uncurry ((\lambda x^{(A \times B) \Rightarrow C}. \lambda a^A . \lambda b^B . x\langle a,b \rangle) f)  \langle u,v \rangle \\
		\hookrightarrow& \\
		 & uncurry (\lambda a^A . \lambda b^B . f\langle a,b \rangle)  \langle u,v \rangle \\
		=& \\
		 & (\lambda x^{A \Rightarrow B \Rightarrow C}. \lambda y^{A \times B} . x(\pi_1 y)(\pi_2 y)) (\lambda a^A . \lambda b^B . f\langle a,b \rangle)  \langle u,v \rangle \\
		\hookrightarrow& \\
		& (\lambda y^{A \times B} . (\lambda a^A . \lambda b^B . f\langle a,b \rangle)(\pi_1 y)(\pi_2 y)) \langle u,v \rangle \\
		\hookrightarrow& \\
		& (\lambda a^A . \lambda b^B . f\langle a,b \rangle)(\pi_1 \langle u,v \rangle)(\pi_2 \langle u,v \rangle) \\
		\hookrightarrow& \\
		& (\lambda a^A . \lambda b^B . f\langle a,b \rangle) u \; v \\
		\hookrightarrow& \\
		& f\langle u,v \rangle \\
	\end{align*}
	De forma similar se puede probar que $curry \circ uncurry = id_{A \Rightarrow B \Rightarrow C}$
	
	Di Cosmo \cite{MSCSSurvey05} caracterizó los conjuntos mínimos de isomorfismos que permiten construir todos los demás a partir de reglas de congruencia y transitividad.
	Se escribe $A \equiv B$ cuando $A$ y $B$ sean isomorfos.
	
	\begin{table}[H]
		\centering
		\begin{minipage}{0.7\linewidth}
			\begin{enumerate}
				\item[swap] $A \Rightarrow (B \Rightarrow  C) \equiv B \Rightarrow (A \Rightarrow  C)$ \tikzmark{swap}
				
				\item $A \times B \equiv B \times A$ \tikzmark{topTh1xT}
				\item $A \times (B \times C) \equiv (A \times B) \times C$
				\item $(A \times B) \Rightarrow C \equiv A \Rightarrow (B \Rightarrow C)$
				\item $A \Rightarrow (B \times C) \equiv (A \Rightarrow B) \times (A \Rightarrow C)$
				
				\item $A \times \textbf{T} \equiv A$
				\item $A \Rightarrow \textbf{T} \equiv \textbf{T}$
				\item $\textbf{T} \Rightarrow A \equiv A$ \tikzmark{botTh1xT}
				
				\item $\forall X. \forall Y. A \equiv \forall Y. \forall X. A$ \tikzmark{topTh2}
				\item $\forall X.A \equiv \forall Y.A [Y/X]$
				\item $\forall X. (A \Rightarrow B) \equiv A \Rightarrow \forall X.B]$ \tikzmark{botTh2}
				\item $\forall X. (A \times B) \equiv \forall X.A \times \forall X.B$
				\item $\forall X.\textbf{T} \equiv \textbf{T}$ \tikzmark{botTh2xT}
				
				\item[split] $\forall X. (A \times B) \equiv \forall X \forall Y.A \times \forall X. (B [Y/X])$ \tikzmark{split}
				
			\end{enumerate}
	
			\begin{tikzpicture}[overlay, remember picture]
				\draw [decoration={calligraphic brace,amplitude=0.4em},very thick,decorate]
				let \p1=(pic cs:swap) in
				(19em, \y1+1em) -- node[right=0.6em] {$Th^1$} (19em, \y1-0.6em);
				
				\draw [decoration={calligraphic brace,amplitude=0.4em},very thick,decorate]
				let \p1=(pic cs:topTh1xT), \p2=(pic cs:botTh1xT) in
				(19em, \y1+0.8em) -- node[right=0.6em] {$Th^1_{\times T}$} (19em, \y2);
				
				\draw [decoration={calligraphic brace,amplitude=0.4em},very thick,decorate]
				let \p1=(pic cs:topTh2), \p2=(pic cs:botTh2) in
				(15em, \y1+0.8em) -- node[right=0.6em] {+ swap = $Th^2$} (15em, \y2);
				
				\draw [decoration={calligraphic brace,amplitude=0.4em},very thick,decorate]
				let \p1=(pic cs:topTh1xT), \p2=(pic cs:botTh2xT) in
				(23em, \y1+0.8em) -- node[right=0.6em] {$Th^2_{\times T}$} (23em, \y2);
				
				\draw [decoration={calligraphic brace,amplitude=0.4em},very thick,decorate]
				let \p1=(pic cs:topTh1xT), \p2=(pic cs:split) in
				(27em, \y1+0.8em) -- node[right=0.6em] {$-10, 11 = Th^{ML}$} (27em, \y2);
			\end{tikzpicture}
		\end{minipage}
		\caption{Isomorfismos de tipo en cálculo lambda tipado}
	\end{table}
	
	\subsection{Sistema I}
	Sistema I \cite{system-i} es un lenguaje de pruebas para el fragmento de la lógica con $\Rightarrow$ y $\wedge$, que se corresponde con lambda cálculo simplemente tipado con pares.
	El conjunto de isomorfismos que abarca este sistema es denominado $Th^1_\times$.
	El primer paso para la internalización de los isomorfismos es la definición de una nueva regla de tipado llamada $(\equiv)$
	
	\[ \frac{A \equiv B \quad \Gamma \vdash r:A}{\Gamma \vdash r:B} (\equiv) \]
	
	Esta regla permite emplear términos $r:A$ en cualquier lugar que se necesite un tipo isomorfo a $A$. Por ejemplo:
	
	\begin{prooftree*}
		\hypo{ \Gamma\vdash r: A }
		\infer1[($\Rightarrow_i$)]{ \Gamma\vdash \lambda x.r: C \Rightarrow A }
		\hypo{ \Gamma\vdash s: B }
		\infer1[($\Rightarrow_i$)]{ \Gamma\vdash \lambda x.s: C \Rightarrow B }
		\infer2[($\times_i$)]{ \Gamma\vdash \langle \lambda x.r, \lambda x.s \rangle : (C \Rightarrow A) \times (C \Rightarrow B) }
		\infer1[($\equiv$)]{ \Gamma\vdash \langle \lambda x.r, \lambda x.s \rangle : C \Rightarrow (A \times B) }
		\hypo{ \Gamma\vdash t: C }
		\infer2[($\Rightarrow_e$)]{ \Gamma\vdash \langle \lambda x.r, \lambda x.s \rangle \; t : A \times B }
	\end{prooftree*}
	
	La introducción de una relación de equivalencia en el nivel de los tipos, necesariamente deberá tener consecuencias en el nivel de los términos.
	Con las reglas de reducción usuales, un término como el del ejemplo anterior estaría en forma normal.
	Entonces, el siguiente paso es extender la relación de reducción con isomorfismos a nivel términos.
	Estas nuevas reglas permiten desatascar los términos que tipamos usando $(\equiv)$.
	Por ejemplo, para reducir el término del ejemplo anterior, es necesario definir la siguiente equivalencia de términos $\langle \lambda x^A.r, \lambda x^A.s \rangle \leftrightarrows \lambda x^A. \langle r, s \rangle$:
	\begin{align*}
		& \langle \lambda x.r, \lambda x.s \rangle \; t \\
		\leftrightarrows& \\
		& (\lambda x^A. \langle r, s \rangle) t \\
		\hookrightarrow& \\
		& \langle r[t/x], s[t/x] \rangle
	\end{align*}
	
	Es importante destacar que dependiendo del conjunto de isomorfismos de términos que se incluyen, se obtienen sistemas de cálculo con distintas propiedades, incluir demasiados puede desencadenar en no terminación, y si se incluyen pocos pueden aparecer eliminaciones en formas normales.
	
	A continuación, se presentan las reglas propuestas por Sistema I, las cuales fueron elegidas con el objetivo de obtener un cálculo fuertemente normalizante y consistente:
	
	\begin{figure}[ht!]
		\begin{align*}
			A \times B &\equiv B \times A \\
			A \times (B \times C) &\equiv (A \times B) \times C \\
			(A \times B) \Rightarrow C &\equiv A \Rightarrow (B \Rightarrow C) \\
			A \Rightarrow (B \times C) &\equiv (A \Rightarrow B) \times (A \Rightarrow C)
		\end{align*}
		
		\caption{Isomorfismos de tipo en Sistema I}
	\end{figure}
	
	\begin{figure}[ht!]
		\centering
		\begin{align}
			\langle r,s \rangle &\rightleftarrows \langle s,r \rangle \tag{\textsc{comm}} \\
			\langle r, \langle s,t \rangle \rangle &\rightleftarrows \langle \langle r, s \rangle, t \rangle \tag{\textsc{asso}} \\
			\lambda x^A \langle r,s \rangle &\rightleftarrows \langle \lambda x^A.r, \lambda x^A.s \rangle \tag{$\textsc{dist}_{\lambda}$} \\
			\langle r,s \rangle t &\rightleftarrows \langle r t, s t \rangle \tag{$\textsc{dist}_{app}$} \\
			r \langle s, t \rangle &\rightleftarrows r s t \tag{\textsc{curry}}
		\end{align}
		
		\begin{prooftree}
			\hypo{\lambda x.t \rightleftarrows \lambda x.r}
			\infer1{ t \rightleftarrows r }
		\end{prooftree} \quad
		\begin{prooftree}
			\hypo{ts \rightleftarrows rs}
			\infer1{ t \rightleftarrows r }
		\end{prooftree} \quad
		\begin{prooftree}
			\hypo{st \rightleftarrows sr}
			\infer1{ t \rightleftarrows r }
		\end{prooftree} \\ \vspace{1em}
		\begin{prooftree}
			\hypo{\langle t, s \rangle \rightleftarrows \langle r, s \rangle}
			\infer1{ t \rightleftarrows r }
		\end{prooftree} \quad
		\begin{prooftree}
			\hypo{\langle s, t \rangle \rightleftarrows \langle s, r \rangle}
			\infer1{ t \rightleftarrows r }
		\end{prooftree} \quad
		\begin{prooftree}
			\hypo{\pi_A t \rightleftarrows \pi_A r}
			\infer1{ t \rightleftarrows r }
		\end{prooftree}
		
		\caption{Reglas de equivalencia entre términos}
	\end{figure}
	
	\begin{figure}[ht!]
		\centering
		\begin{prooftree}
			\infer0[($ax$)]{ \Gamma, x:A \vdash x:A }
		\end{prooftree}
		\quad
		\begin{prooftree}
			\hypo{A \equiv B}
			\hypo{\Gamma \vdash r:A}
			\infer2[($\equiv$)]{ \Gamma \vdash r:B }
		\end{prooftree}
		\vspace{1em}
		\\
		\begin{prooftree}
			\hypo{\Gamma, x:A \vdash r:B}
			\infer1[($\Rightarrow_i$)]{ \Gamma \vdash \lambda x.r : A \Rightarrow B }
		\end{prooftree}
		\quad
		\begin{prooftree}
			\hypo{\Gamma \vdash \lambda x.r : A \Rightarrow B}
			\hypo{\Gamma \vdash s:A}
			\infer2[($\Rightarrow_e$)]{ \Gamma \vdash rs : B }
		\end{prooftree}
		\vspace{1em}
		\\
		\begin{prooftree}
			\hypo{\Gamma \vdash r:A}
			\hypo{\Gamma \vdash s:B}
			\infer2[($\times_i$)]{ \Gamma \vdash \langle r, s \rangle : A \times B }
		\end{prooftree}
		\quad
		\begin{prooftree}
			\hypo{\Gamma \vdash \langle r, s \rangle : A \times B}
			\infer1[($\times_e$)]{ \Gamma \vdash \pi_A\langle r, s \rangle : A }
		\end{prooftree}
		\caption{Reglas de tipado}
	\end{figure}
	
	El siguiente paso surge de notar que las nuevas reglas introducen problemas en la reducción clásica.
	Por un lado, las reglas de proyección $\pi_1$ y $\pi_2$ indexan el par a través de la posición de los elementos, pero el isomorfismo $\textsc{comm}$ permite cambiar el orden de un par, permitiendo así proyectar cualquiera de los dos elementos:
	
	\begin{align*}
		\langle r, s \rangle& \hookrightarrow_{\pi_1} r \\
		\langle r, s \rangle& \leftrightarrows_{\textsc{comm}} \langle s, r \rangle \hookrightarrow_{\pi_1} s
	\end{align*}
	
	Esto supone un problema para la preservación de tipos.
	La solución es indexar el elemento a través de su tipo, por lo que se define una nueva regla:
	
	\[ \text{si} \; r:A \quad \pi_A \langle r, s \rangle \hookrightarrow_{\pi} r \]
	
	Una consecuencia importante es que esta regla introduce no determinismo en el cálculo.
	Si $r$ y $s$ tienen tipo $A$, entonces $\pi_A \langle r, s \rangle$ puede reducir indistintamente a cualesquiera de los dos términos.
	Sin embargo, es posible codificar una proyección determinista incluso cuando ambos términos son del mismo tipo, por ejemplo, el par $\langle r, s \rangle: A \times A$
	se codifica como $\langle \lambda x^\mathbb{X}.r, \lambda x^\mathbb{Y}.s \rangle : \mathbb{X} \Rightarrow A \times \mathbb{Y} \Rightarrow A$.
	Y la proyección $\pi_1 \langle r, s \rangle$ se codifica como $(\pi_{\mathbb{X} \Rightarrow A} \langle \lambda x^\mathbb{X}.r, \lambda x^\mathbb{Y}.s \rangle) y^\mathbb{X}$, donde $\mathbb{X}$ y $\mathbb{Y}$ son dos tipos distintos, y $y^\mathbb{X}$ es cualquier elemento de tipo $\mathbb{X}$.
	De forma análoga se puede codificar $\pi_2$.

	
	La $\beta$-reducción clásica también entra en conflicto con la preservación de tipos.
	Por ejemplo, el término $(\lambda x^A . \lambda y^B . r)ts$ donde $t:B$ y $s:A$ está bien tipado, pero para reducirlo correctamente primero se deben aplicar equivalencias para intercambiar el orden de $t$ y $s$.
	Sin embargo, no hay nada que impida aplicar la regla $\beta$, lo cual podría terminar reduciendo a un tipo equivocado.
	Para solucionar esto, se modifica la $\beta$-reducción:
	
	\[ \text{si} \; s:A \quad (\lambda x^A.r) s \hookrightarrow_{\beta} r[s/x] \]
	
	Por último se define la relación de reducción módulo isomorfismos:
	
	\[ \rightsquigarrow \; = \; \leftrightarrows^* \circ \hookrightarrow \circ \leftrightarrows^* \]
	
	Es decir, que primero los términos son transformados a una forma equivalente donde sea posible aplicar las eliminaciones, y luego se aplican las $\beta$-reducciones y proyecciones.
	
	
	\subsection{SIP}
	Sistema I Polimórfico \cite{sip}, es una extensión que agrega polimorfismos a Sistema I, toma algunos de los isomorfismos del conjunto axiomático $Th^2_\times$.
	Desde el punto de vista de la lógica, agrega el conector $\forall$, y en cuanto a la programación, agrega la gramática de tipos y términos correspondientes a Sistema F con pares.
	
	El trabajo presenta la técnica utilizada para obtener las equivalencias de términos inducidas por un isomorfismo de tipos.
	Dado un isomorfismo de tipos con dos constructores involucrados, se construyen términos aplicando de diferentes maneras las reglas de tipado relacionadas con los constructores.
	Para cualquier par de conectivas, tenemos cuatro posibles formas de combinar sus reglas de tipado: introducción-introducción, introducción-eliminación, eliminación-introducción, y eliminación-eliminación.
	Cada una induce una equivalencia, y cada lado de la equivalencia estará dado por el orden en que se apliquen las conectivas.
	
	Por ejemplo, el isomorfismo $A \Rightarrow (B \times C) \equiv (A \Rightarrow B) \times (A \Rightarrow C)$ emplea los conectores $\Rightarrow$ y $\times$, SIP incluye las siguientes dos equivalencias:
	
	\begin{itemize}
		\item Introducción de $\Rightarrow$ e introducción de $\times$: $\lambda x.\langle r,s \rangle \leftrightarrows \langle \lambda x.r, \lambda x.s \rangle$

		\begin{center}
			\begin{prooftree}
				\hypo{\Gamma, x:A \vdash r:B}
				\hypo{\Gamma, x:A \vdash s:C}
				\infer2[($\times_i$)]{ \Gamma, x:A \vdash \langle r, s \rangle : B \times C }
				\infer1[($\Rightarrow_i$)]{ \Gamma \vdash \lambda x. \langle r, s \rangle : A \Rightarrow B \times C }
			\end{prooftree}
			\\
			\vspace{1em}
			\begin{prooftree}
				\hypo{\Gamma, x:A \vdash r:B}
				\infer1[($\Rightarrow_i$)]{ \Gamma \vdash \lambda x.r : A \Rightarrow B }
				\hypo{\Gamma, x:A \vdash s:C}
				\infer1[($\Rightarrow_i$)]{ \Gamma \vdash \lambda x.s : A \Rightarrow C }
				\infer2[($\times_i$)]{ \Gamma \vdash \langle \lambda x.r, \lambda x.s \rangle : (A \Rightarrow B) \times (A \Rightarrow C) }
				\infer1[($\equiv$)]{ \Gamma \vdash \langle \lambda x.r, \lambda x.s \rangle : A \Rightarrow (B \times C) }
			\end{prooftree}
		\end{center}
		
		\item Eliminación de $\Rightarrow$ e introducción de $\times$: $\langle r,s \rangle t \leftrightarrows \langle rt, st \rangle$
		
		\begin{center}
			\begin{prooftree}
				\hypo{\Gamma \vdash r: A \Rightarrow B}
				\hypo{\Gamma \vdash s: A \Rightarrow C}
				\infer2[($\times_i$)]{ \Gamma \vdash \langle r, s \rangle : (A \Rightarrow B) \times (A \Rightarrow C) }
				\infer1[($\equiv$)]{ \Gamma \vdash \langle r, s \rangle : A \Rightarrow (B \times C) }
				\hypo{\Gamma \vdash t: A}
				\infer2[($\Rightarrow_e$)]{ \Gamma \vdash \langle r, s \rangle t : B \times C }
			\end{prooftree}
			\\
			\vspace{1em}
			\begin{prooftree}
				\hypo{\Gamma \vdash r: A \Rightarrow B} \hypo{\Gamma \vdash t: A}
				\infer2[($\Rightarrow_e$)]{ \Gamma \vdash rt : B }
				\hypo{\Gamma \vdash s: A \Rightarrow C} \hypo{\Gamma \vdash t: A}
				\infer2[($\Rightarrow_e$)]{ \Gamma \vdash st : C }
				\infer2[($\times_i$)]{ \Gamma \vdash \langle rt, st \rangle :  B \times C }
			\end{prooftree}
		\end{center}
	\end{itemize}
	

	\subsection{$\lambda^+$}
	$\lambda^+$ \cite{lambda-plus} es una implementación en Haskell de una extensión que agrega naturales y recursión general a Sistema I.
	Este trabajo muestra las dificultades de implementar un sistema de tipos módulo isomorfismos y las aplicaciones prácticas de un lenguaje de programación con dichas capacidades.
	Por ejemplo, utilizando $\textsc{curry}$, $\textsc{comm}$ y $\textsc{asso}$ es posible aplicar parcialmente los argumentos de una función en cualquier orden.
	
	Un detalle interesante es la adición de una nueva regla llamada $\textsc{split}$ que no surge de ningún isomorfismo, sino que es necesaria para reducir términos que de otra forma quedarían atascados.
	Esto muestra que desde el punto de vista de la implementación, puede ser necesario agregar nuevas equivalencias de términos para lograr reducir a una forma normal.
	% explicar que introduce el split, es necesario agregar o eliminar isos para lograr la reduccion 

	
	\chapter{Preliminares}
	
	\section{Tipos dependientes}
	Un ejemplo clásico que se suele dar a la hora de presentar los tipos dependientes, es el de los vectores de largo $n$:
	
	\begin{lstlisting}[mathescape, language=Haskell]
	data Vec A (n: $\mathbb{N}$) where
	  nil : Vec A 0
	  cons : A $\rightarrow$ Vec A n $\rightarrow$ Vec A (suc n)
	\end{lstlisting}
	
	Es importante notar que el segundo parámetro de \verb|Vec| no es el tipo $\mathbb{N}$, sino un término de tipo $\mathbb{N}$, por ejemplo, \verb|Vec| $\mathbb{N}$ \verb|3| representa el tipo de los vectores de naturales de largo 3.
	Esto quiere decir que dentro de los tipos pueden aparecer términos, lo cual permite escribir programas más precisos y seguros.
	
	Para entender la practicidad de un sistema de tipos con dicho nivel de especificidad, se comparan los siguientes programas:
	\begin{lstlisting}[mathescape, language=Haskell]
	zeroesL : $\mathbb{N}$ $\rightarrow$ List $\mathbb{N}$
	zeroesL 0       = []
	zeroesL (suc n) = 0 :: (zeroesL n)
	
	zeroesV : (n: $\mathbb{N}$) $\rightarrow$ Vec $\mathbb{N}$ n
	zeroesV 0       = nil
	zeroesV (suc n) = cons 0 (zeroesV n)
	\end{lstlisting}
	
	Notar que el tipo de $zeroesV$ es dependiente e introduce una variable.
	Si bien la implementación dada para $zeroesL$ es correcta, nada impediría simplemente retornar \verb|[]| en todos los casos, por el contrario, en el caso \verb|(suc n)| de $zeroesV$ se estaría cometiendo un error de tipo si se tratara de retornar \verb|[]|, ya que se espera un término de tipo \verb|Vec| $\mathbb{N}$ \verb|(suc n)| y la lista vaciá tiene tipo \verb|Vec| $\mathbb{N}$ \verb|0|.
	De cierta forma el tipo de las funciones está guiando su implementación, impidiendo, en este caso, retornar un vector de largo incorrecto.
	
	Otra comparación que pone en evidencia la correctitud de los lenguajes con tipos dependientes, es la diferencia entre el operador de indexación de listas y vectores.
	
	\begin{lstlisting}[mathescape, language=Haskell]
	_!!_ : List A $\rightarrow$ $\mathbb{N}$ $\rightarrow$ Maybe A
	[] !! n              = nothing
	(x :: xs) !! zero    = just x
	(x :: xs) !! (suc n) = xs !! n
	\end{lstlisting}
	
	Antes de presentar la implementación para vectores, es necesario definir el tipo de datos de los conjuntos finitos:
	
	\begin{lstlisting}[mathescape, language=Haskell]
	data Fin $\mathbb{N}$ where
	  zero : Fin (suc n)
	  suc  : Fin n $\rightarrow$ Fin (suc n)
	\end{lstlisting}
	
	Cada tipo \verb|Fin n| está habitado por $n$ elementos, estos serían, el elemento \verb|zero| más el constructor \verb|suc| combinado con los $n-1$ elementos de \verb|Fin (n-1)|.
	Notar que \verb|Fin 0| es un conjunto vacío, es decir que no existe ningún término con dicho tipo, o dicho de otra forma, el tipo \verb|Fin 0| no está habitado por ningún término.
	Luego, un vector de largo $n$ estará indexado por los elementos del conjunto \verb|Fin n|, que tiene cardinalidad exactamente igual a $n$.
	
	\begin{lstlisting}[mathescape, language=Haskell]
	_!!v_ : {n : $\mathbb{N}$} $\rightarrow$ Vec A n $\rightarrow$ Fin n $\rightarrow$ A
	(cons x v) !!v zero  = x
	(cons x v) !!v suc i = v !!v i
	\end{lstlisting}
	
	Notar que en la implementación ya no aparece el caso \verb|nil|, porque eso implicaría que $n = 0$, pero el parámetro $n$ del tipo dependiente está forzando al argumento \verb|Fin| a tener la misma cantidad de elementos que el vector, por lo que dicho argumento debería ser un elemento de \verb|Fin 0|, el cual es un conjunto vació.
	Esto es lo que se denomina un ``patrón absurdo'', y como es imposible que dicho patrón ocurra, se lo excluye de la implementación.
	
	Utilizando estos tipos es imposible tratar de acceder a un elemento que no esté en el rango del vector.
	Lo más interesante es que los invariantes son verificados estáticamente por el sistema de tipos en tiempo de compilación.
	Un término que trata de romper alguna invariante, estará mal tipado, por lo que no es posible construirlo.

	
	\subsection{Lambda cube}
	Hasta ahora se presentaron distintos tipos de cálculo lambda que se podrían agrupar en dos grandes categorías, el simplemente tipado ($\lambda_{\to}$), y el cálculo lambda polimórfico, también denominado \textit{Sistema F} o cálculo lambda de segundo orden ($\lambda 2$).
	
	La diferencia fundamental entre estos dos, son las dependencias entre tipos y términos que se permiten.
	Por ejemplo $\lambda_{\to}$ solo permite que las abstracciones liguen términos, es decir, los términos solo pueden depender de otros términos.
	Luego, $\lambda 2$ añade nuevas reglas de tipado que permiten construir términos que dependen de tipos.
	
	La inclusión de tipos dependiente, es decir, construcciones que permiten a los tipos depender de términos, da como resultado un cálculo denominado $\lambda\Pi$.
	Si se incluyen estas tres dependencias, es decir, términos que depender de términos o tipos y tipos que dependen de términos, se obtiene el cálculo lambda dependiente de segundo orden ($\lambda\Pi 2$).
	
	Notar como cada dependencia es, en cierta forma, ortogonal a las demás, y cada cálculo obtenido a medida que se añaden dependencias, es un superconjunto de los cálculos anteriores, es decir, se obtienen generalizaciones cada vez más grandes.
	Se pueden visualizar las distintas dimensiones utilizando el cubo lambda \cite{lambda_cube}:
	
	\begin{figure}[H]
		\centering
		\begin{tikzpicture}
			\matrix (m) [matrix of math nodes,
			row sep=3em, column sep=2.4em,
			text height=1.5ex,
			text depth=0.25ex]{
							& \lambda\omega             &              & \lambda C					  \\
				\lambda 2   &                           & \lambda\Pi 2                                \\
							& \lambda\underline{\omega} &              & \lambda\Pi\underline{\omega} \\
				\lambda_{\to}&                           & \lambda\Pi 								  \\
			};
			\path[-{Latex[length=2.5mm, width=1.5mm]}]
			(m-1-2) edge (m-1-4)
			(m-2-1) edge (m-2-3)
					edge (m-1-2)
			(m-3-2) edge (m-1-2)
					edge (m-3-4)
			(m-4-1) edge (m-2-1)
					edge (m-3-2)
					edge (m-4-3)
			(m-3-4) edge (m-1-4)
			(m-2-3) edge (m-1-4)
			(m-4-3) edge (m-3-4)
					edge (m-2-3);
		\end{tikzpicture}
		\caption{El cubo lambda representa las dependencias entre tipos y términos como dimensiones ortogonales, las flechas corresponden a la relación $\subsetneq$.}
	\end{figure}
	
	\begin{itemize}
		\item $(\uparrow)$: términos que dependen de tipos.
		El polimorfismo incrementa el poder de cálculo del sistema, ya que permite la auto-aplicación preservando la propiedad de terminación, por lo tanto, es posible representar cualquier función recursiva primitiva.
		\item $(\rightarrow)$: tipos que dependen de términos.
		La inclusión de tipos dependientes no aumenta el poder de cálculo, pero permite expresar mediante en el sistema de tipos propiedades sobre los programas.
		Como se explicará más adelante, los tipos dependientes permiten dar un salto a un sistema, que desde el punto de vista de la lógica, es equivalente a la lógica de predicados.
		\item $(\nearrow)$: tipos que dependen de tipos.
		Corresponde a los constructores de tipos, es decir, operadores que permiten crear nuevos tipos a partir de otros tipos más básicos.
		El cálculo $\lambda\omega$, que permite representar funciones polimórficas y constructores de tipos, es considerado como la base de muchos lenguajes de programación funcionales.
	\end{itemize}
	
	El sistema que incluye a todos los demás, es denominado Cálculo de Construcciones ($\lambda C$), este posee el mayor poder de cómputo y expresividad.
	Si bien los sistemas de tipos imponen restricciones sobre las construcciones que son posibles en los sistemas de cálculo, permiten obtener propiedades interesantes.
	Por ejemplo, la propiedad de terminación es necesaria para que la lógica representada por estos cálculos sea consistente.
	En particular, $\lambda C$ tiene un sistema de tipos lo suficientemente expresivo como para representar la lógica de predicados de alto orden, mientras que es lo suficientemente restrictivo como para que dicha lógica sea consistente.
	
	
	\section{Propositions as Types}
	El paradigma de ``proposiciones como tipos'' describe la correspondencia entre la lógica y los lenguajes de programación.
	Básicamente, dice que a cada proposición en la lógica le corresponde un tipo, y viceversa.
	De hecho, esta relación es más profunda, ya que a cada prueba de una proposición dada, le corresponde un programa del tipo correspondiente, y viceversa.
	Es decir, ``pruebas como programas''.
	Incluso, es más profunda aún, en el sentido de que para cada forma de simplificar una prueba, existe una forma correspondiente de evaluar un programa, y viceversa.
	Por lo que tenemos, ``simplificación de pruebas como evaluación de programas''.
	
	Tal como lo explica Wadler en su artículo \cite{pas}, no se trata de una simple biyección entre proposiciones y tipos, sino de un verdadero isomorfismo que preserva la compleja estructura de pruebas y programas, simplificaciones y evaluaciones.
	
	Este principio surge de las observaciones realizadas por Curry\cite{Curry} sobre la lógica proposicional, y más tarde extendidas por Howard\cite{Howard} a la lógica de predicados.
	La clave de esta extensión es la introducción de los tipos dependientes para representar los predicados y cuantificadores en la lógica de predicados.

	Las correspondencias que surgen de esta interpretación pueden resumirse de la siguiente forma:
	
	\begin{itemize}
		\item La conjunción $A \wedge B$ corresponde al par $A \times B$.
		Una prueba de la proposición $A \wedge B$ consiste de una prueba de $A$ y una prueba de $B$.
		
		\item La disyunción $A \vee B$ corresponde la suma disyunta $A + B$.
		Una prueba de la proposición $A \vee B$ consiste de una prueba de $A$ o una prueba de $B$.
		
		\item La implicación $A \Rightarrow B$ corresponde al espacio de funciones $A \rightarrow B$.
		Una prueba de la proposición $A \Rightarrow B$ consiste de una función que dada una prueba de $A$ devuelve una prueba de $B$.
		
		\item El cuantificador existencial $\exists x:A.B$ corresponde al tipo $\Sigma x:A.B$.
		Básicamente, esto es una familia de tipo indexada por $a : A$ donde a cada término $a$ le corresponde un tipo $B(a)$.
		Los elementos canónicos de $\Sigma x:A.B$ son pares dependientes $\langle a, b \rangle$ donde $a:A$ y $b:B(a)$.
		Cuando $B(a)$ es una función constante, este tipo es equivalente al producto cartesiano $A \times B$.
		
		
		\item El cuantificador universal $\forall x:A.B$ corresponde $\Pi x:A.B$, al igual que para el tipo $\Sigma$, $B$ está indexado por los términos de tipo $A$.
		Los elementos canónicos de $\Pi x:A.B$ son funciones dependientes $a \rightarrow B(a)$.
		Cuando $B(a)$ es una función constante, el tipo $\Pi$ es equivalente al tipo de las funciones ordinarias $A \rightarrow B$.
	\end{itemize}
	

	\section{Intuitionistic Type Theory}
	La teoría de tipos intuicionista, también llamada teoría de tipos de Martin-Löf \cite{ITT} propone un sistema lógico formal y los fundamentos filosóficos para las matemáticas constructivas.
	
	Directamente influenciado por las ideas de Howard, Martin-Löf se basó en el principio de proposiciones como tipos y el constructivismo matemático para el desarrollo de su teoría.
	Este constructivismo requiere que las pruebas contengan un ``testigo'', una prueba de una proposición dada es un programa, por lo tanto, las proposiciones son verdaderas cuando su tipo está habitado por algún término.
	Las pruebas son términos que atestiguan la veracidad del teorema, y pueden ser manipulados como cualquier otro término del lenguaje.
	Vistas como programas, las pruebas son procedimientos que al ejecutarlos permiten obtener valores del tipo indicado por la proposición, por este motivo se dice que las pruebas son constructivas.
	
	Esto tiene algunas consecuencias interesantes, por ejemplo, en la lógica clásica, a las proposiciones se les asigna valores de verdad sin importar si existe evidencia directa de que sea verdadera o falsa.
	Esto es lo que comúnmente se denomina ``principio del tercero excluido'', ya que excluye la posibilidad de un tercer valor distinto de verdadero o falso.
	Sin embargo, puede que no siempre sea posible construir una prueba de dicha proposición para cualquier tipo $A$, por lo tanto, no es posible probar $A \vee \neg A$ en la lógica intuicionista.

	
	Se puede pensar a la teoría de tipos intuicionista como un lenguaje de programación funcional donde el sistema de tipos es tan rico que prácticamente cualquier propiedad concebible de un programa puede expresarse como un tipo.
	Todas las funciones de este lenguaje deben ser totales y computables, por lo que todos los programas deben necesariamente cumplir con la propiedad de terminación.
	
	Filosófica y prácticamente, la teoría de tipos de Martin-Löf es un marco fundamental donde las matemáticas constructivas y la programación son, en un sentido profundo, lo mismo.
	
	
	\section{Agda}
	Agda es un lenguaje de programación con tipos dependientes, desarrollado por la Universidad de
	Chalmers (Suiza).
	Debido al paradigma de las proposiciones como tipos, Agda también funciona como un asistente de pruebas.
	A diferencia de otros asistentes, como Coq, carece de un sistema de tácticas, por lo que las pruebas son escritas en un estilo de programación funcional, de hecho su sintaxis es similar a la de Haskell.

	Agda es un lenguaje total, es decir que todos los programas deben terminar, y todos los posibles casos de un pattern matching deben ser cubiertos, de otro modo la lógica sería inconsistente.
	Por este motivo, no todas las funciones recursivas están permitidas, Agda poseé un mecanismo de comprobación de terminación que acepta aquellas funciones que puede probar mecánicamente su terminación.
	
	% TODO: Explicar simbolos, opperadores y Sets (universos)
	
	\section{Indices de DeBruijn}
	Generalmente, los términos en cálculo lambda se presentan utilizando letras para nombrar las variables, por ejemplo:
	\[ \lambda z. (\lambda y. y (\lambda x. x)) (\lambda x. z x) \]
	Esta forma de representación permite ver a simple vista cuáles variables están ligadas y a que abstracción pertenecen, también suelen utilizarse palabras para dar nombres más descriptivos a las variables.
	Se puede notar que la forma de escribir un término no es única, ya que es posible cambiar los nombres de algunas variables sin alterar su significado, por ejemplo, el término $\lambda c. (\lambda b. b (\lambda d. d)) (\lambda a. c a)$ es equivalente al del ejemplo anterior.
	Cuando esto ocurre se dice que los términos son $\alpha$-equivalentes.
	
	El principal problema de esta representación es que para implementar la $\beta$-reducción, se debe tener cuidado de no capturar una variable libre cuando se substituye un término en el cuerpo de una abstracción, en caso de que eso ocurra, se renombra la variable capturada con un nuevo nombre fresco.
	En el siguiente ejemplo la variable $x$ es renombrada a $z$ para evitar la captura:
	\[ (\lambda y. (\lambda x. x y)) x \hookrightarrow_{\beta} (\lambda x. x y)[y := x] = \lambda z. z x \]
	
	Utilizar variables con nombres hace que la implementación se vuelva más engorrosa e ineficiente.
	Una alternativa más adecuada es la representación de DeBruijn \cite{debrujin_index}, que reemplaza los nombres por números naturales llamados \textit{índices de DeBruijn}.
	Por ejemplo, la forma de escribir el término del primer ejemplo con índices es la siguiente:
	
	\[ \textcolor{red}{\lambda} (\textcolor{blue}{\lambda\; 0} \; (\textcolor{orange}{\lambda\; 0})) (\textcolor{green}{\lambda}\; \textcolor{red}{1} \; \textcolor{green}{0}) \]

	Los índices indican cuantas abstracciones se deben ``saltar'' para llegar a la que está ligando la variable.
	Los nombres de las ligaduras ya no son necesarios, por lo que la escritura se simplifica.
	Además, los términos tienen una única representación, es decir, no es necesario tener en cuenta las $\alpha$-equivalencias.
	
	
	\section{Substituciones explícitas}
	Utilizando la representación de DeBruijn, las sustituciones son simplemente mapas de números naturales a términos, es decir que pueden interpretarse como una secuencia infinita de términos.
	Por ejemplo:
	\[ (0\; 1\; 3)\{0\mapsto a, 1\mapsto b, i+2\mapsto i\} \rightarrow a\; b\; 1 \]
	
	Si se quisiera definir la $\beta$-reducción utilizando esta notación, una primera definición sería:
	
	\[ (\lambda a)b \rightarrow_{\beta} a \{ 0 \mapsto b, i+1\mapsto i+1 \} \]
	
	El problema es que al eliminar un $\lambda$ todas las variables libres de $a$ quedaran desfasadas, por lo que se les debe restar uno:
	
	\[ (\lambda a)b \rightarrow_{\beta} a \{ 0 \mapsto b, i+1\mapsto i \} \]
	
	El siguiente problema surge al intentar empujar la substitución dentro de una abstracción, en dicho caso, se debe evitar reemplazar el índice 0 por $b$, por lo que toda la secuencia se mueve un lugar a la derecha:
	
	\[ (\lambda c)\{ 0 \mapsto b, i+1\mapsto i \} = \lambda c \{ 0 \mapsto 0, 1 \mapsto b, i+2\mapsto i+1 \} \]
	
	Un último problema puede presentarse si $b$ tiene variables libres, para evitar que estas sean capturadas por el $\lambda$ de $c$ se les debe sumar uno:
	\[ (\lambda c)\{ 0 \mapsto b, i+1\mapsto i \} = \lambda c \{ 0 \mapsto 0, 1 \mapsto b \{ i \mapsto i+1 \}, i+2\mapsto i+1 \} \]
	
	El siguiente ejemplo muestra la forma correcta de realizar una $\beta$ reducción:
	
	\[
	(\textcolor{red}{\lambda}\; \lambda\; \textcolor{orange}{3}\; \textcolor{red}{1}\; (\textcolor{green}{\lambda\; 0}\; \textcolor{red}{2}))\; (\textcolor{blue}{\lambda}\; \textcolor{orange}{4}\; \textcolor{blue}{0})
	\hookrightarrow_\beta
	\lambda \; \textcolor{orange}{2} \; (\textcolor{blue}{\lambda}\; \textcolor{orange}{5}\; \textcolor{blue}{0})\; (\textcolor{green}{\lambda\; 0}\; (\textcolor{blue}{\lambda}\; \textcolor{orange}{6}\; \textcolor{blue}{0}))\;
	\]
	
	Notar como las variables libres del cuerpo de la abstracción se disminuyen en uno, las variables libres del argumento aumentan en uno por cada $\lambda$ que atraviesan, y las variables ligadas quedan intactas.
	
	
	En \cite{explicit_subs} se presenta el álgebra $\sigma$ y los cuatro operadores que permiten construir estas secuencias.

	\begin{itemize}
		\item $id$ es la substitución identidad $\{i \mapsto i\}$.
		\item $\uparrow$ es el operador shift, y suma uno a cada índice $\{i \mapsto i+1\}$.
		\item $a \cdot s$ es la concatenación del término $a$ a la substitución $s$, $\{0 \mapsto a, i+1 \mapsto s(i)\}$. Por ejemplo $a \cdot id = \{ 0 \mapsto a, 1 \mapsto 0, 2 \mapsto 1, 3 \mapsto 2, \dots \} $
		\item $s \circ t$ corresponde a la composición de substituciones, donde primero se aplica $s$ y luego $t$.
	\end{itemize}
	
	Dada una substitución $s$, se escribe $a[s]$ para denotar la aplicación de la substitución sobre el término $a$.
	\begin{align*}
		n[s] &= s(n) \\
		(a\; b)[s] &= a[s]\; b[s] \\
		(\lambda a)[s] &= \lambda a[0 \cdot (s \; \circ \uparrow)]
	\end{align*}
	
	Finalmente, la $\beta$-reducción se define como:
	\[ (\lambda a)b \hookrightarrow_{\beta} a[b \cdot id] \]
	
	El trabajo Abadi también presenta algunas propiedades algebraicas de los operadores que resultan útiles a la hora de probar propiedades sobre las substituciones:
	\begin{align*}
		0 \; \cdot \uparrow &= id \\
		\uparrow \circ\; (a \cdot s) &= s \\
		0[s] \cdot (\uparrow \circ\; s) &= s \\
		(a \cdot s) \circ t &= a[t] \cdot (s \circ t) \\
	\end{align*}
	
	
	\chapter{Aportes}
	\section{Formalización}
	
	\subsection{Tipos intrínsecos}
	
	Existen dos enfoques fundamentales para la introducción de sistemas de tipos en el cálculo lambda.

	Por un lado, se pueden definir primero los términos y luego los tipos, por lo tanto los términos existen independientemente de los tipos y tienen significado por sí solos.
	Tiene sentido entonces definir el subconjunto de términos para los cuales existe alguna derivación de tipos, a este subconjunto se lo denomina términos ``bien tipados''.
	De hecho, para un término dado pueden existir más de un tipo posible, por ejemplo, la función identidad $\lambda x.x$ puede ser tipada como $A \rightarrow A$ o como $B \rightarrow B$.
	Desde este punto de vista, los juicios de tipos aseguran que los términos poseen ciertas propiedades.
	Este estilo es llamado ``tipos a la Curry''.
	
	Por otro lado, es posible definir los tipos en primer lugar y luego los términos.
	Aquí no tiene sentido hablar de términos ``bien tipados'', ya que no pueden existir los términos ``mal tipados''.
	Por lo tanto, todo el significado recae sobre los juicios de tipo, en lugar de los términos.
	En cierta forma, los términos y las reglas de tipo están entrelazados.
	Aquí, las derivaciones de tipos son únicas, puesto que los términos $\lambda x^A.x$ y $\lambda x^B.x$ se consideran distintos.
	A este enfoque se lo denomina ``tipos a la Church''.
	
	Reynolds \cite{reynolds_1998} acuñó las expresiones \textit{tipos intrínsecos} y \textit{tipos extrínsecos} para referirse a cada uno de estos dos enfoques.
	
	Gran parte de la formalización presentada en este trabajo está basada y adaptada a partir de un libro de Philip Wadler \cite{plfa}.
	% Explicar la diferencia entre Curry style y Church style, y como nos ayuda tener tipos intrínsecos. % Acá hay muchas referencias https://plfa.github.io/DeBruijn/
	
	\subsection{Cálculo lambda con pares y tipo Top}
	
	En primera instancia se definen los tipos del lenguaje, existen cuatro constructores de tipos.
	Por un lado, los tipos base son, el tipo atómico \AgdaInductiveConstructor{$\tau$} y el tipo top \AgdaInductiveConstructor{$\top$}.
	Y, por otro lado, el tipo de las funciones \AgdaInductiveConstructor{$\_\Rightarrow\_$} y los pares \AgdaInductiveConstructor{$\_\times\_$}.

	\begin{codigo}
		Tipo de dato de los tipos
		\input{code/type.tex}
	\end{codigo}
	
	Dado que se utiliza la representación de De Brujin, los entornos de tipado, simplemente se formalizan como listas de tipos.
	Al contrario de las listas normales, los entornos se leen de derecha a izquierda.
	
	Luego se formalizan las variables intrínsecamente tipadas, que son representadas por los índices propiamente dichos.
	
	\begin{codigo}
		Tipo de dato de los contextos de tipado y variables intrínsecamente tipadas.
    	\ExecuteMetaData[code/context.tex]{ctx}
	\end{codigo}
	
	Se escribe \AgdaBound{$\Gamma$} \AgdaInductiveConstructor{$\ni$} \AgdaBound{A}, para el tipo de las variables que tienen tipo \AgdaBound{A} en el entorno de tipado \AgdaBound{$\Gamma$}.
	Por ejemplo: 
	
	\ExecuteMetaData[code/context.tex]{example}
	
	A continuación se presentan los juicios de tipado, debido a que se utilizan tipos intrínsecos, estos también representaran a los términos del lenguaje.
	
	\begin{codigo}
		Tipo de dato de los términos
		\input{code/term.tex}
	\end{codigo}
	
	Notar que el constructor \AgdaInductiveConstructor{$[\_]\equiv\_$} corresponde a la regla de tipado $(\equiv)$ de Sistema-I.
	En el constructor \AgdaInductiveConstructor{$\pi$} se observa otro detalle importante, además de tomar como argumento el tipo \AgdaBound{C}, toma un argumento implícito que funciona como evidencia de que el tipo \AgdaBound{C} es o bien igual al tipo \AgdaBound{A}, o bien igual al tipo \AgdaBound{B}.
	Para ello se utilizan el tipo suma y la igualdad proposicional que están definidos en la librería estándar de Agda.
	
	
	Aquí se introducen las definiciones de los renombres de variables, substitución de variables y operadores del álgebra-$\sigma$ presentados en capítulos anteriores.
	
	\ExecuteMetaData[code/subs.tex]{operators}
	
	Los renombres son simplemente funciones que mapean las variables de un entorno a otro preservando el tipo de las mismas.
	Por otro lado, las substituciones mapean cada variable de un entorno a un término que tenga el mismo tipo que dicha variable.
	Se pueden pensar a estas substituciones como las secuencias que se utilizaran para reemplazar las variables libres en los cuerpos de las abstracciones cuando se realice una $\beta$-reducción. 
	
	La implementación de las substituciones explícitas se divide en dos partes.
	Primero se implementa la operación \AgdaFunction{rename} que dado una función de renombrado $\rho$ y un término, aplica el renombre de variables a dicho término.
	Se debe tener cuidado de no capturar el índice 0 cuando se empuja el renombre debajo de una abstracción.
	Por este motivo, se define la función \AgdaFunction{ext} que toma un renombre y retorna uno nuevo con los entornos extendidos.
	Notar que esta definición sigue la forma propuesta por Abadi: $Z \cdot (\rho \; \circ S\_)$
	
	\ExecuteMetaData[code/subs.tex]{rename}
	
	Una vez implementada la aplicación de renombres, se puede implementar la aplicación de substituciones.
	De forma análoga, se define una función \AgdaFunction{exts} que extiende la sustitución cuando se atraviesa una abstracción.
	Utilizando la notación del álgebra-$\sigma$, se puede observar que aquí también se sigue la misma estructura: $`Z \cdot (\sigma \; \circ \text{rename } S\_)$.
	
	Luego se define la substitución simple \AgdaOperator{\AgdaFunction{$\_[\_]$}}, que dato un término \AgdaBound{N} cuya primera variable libre es de tipo \AgdaBound{B} y un término \AgdaBound{M} de tipo \AgdaBound{B}, cierra el índice 0 de \AgdaBound{N} utilizando \AgdaBound{M}.
	
	\ExecuteMetaData[code/subs.tex]{subst}
	
	Notar las similitudes entre la definición de \AgdaFunction{rename} y \AgdaFunction{subst}, esto se debe a que los renombres son un caso particular de substitución, donde todos los términos retornados por la substitución son variables.
	Esta implementación está basada en la técnica de McBride \cite{ren-sub}, donde los renombres de variables y substituciones son dos instancias de una misma operación de recorrido.
	El motivo principal por el cual es necesario implementar \AgdaFunction{rename}, es que si se quisiera definir \AgdaFunction{exts} utilizando \AgdaFunction{subst} (\AgdaSymbol{$\lambda$} \AgdaBound{v} \AgdaSymbol{$\rightarrow$} \AgdaInductiveConstructor{`} (\AgdaInductiveConstructor{S} \AgdaBound{v})) (\AgdaBound{$\sigma$} \AgdaBound{x}), la llamada recursiva sería sobre el término retornado por $\sigma$, de modo que el chequeo de terminación de Agda fallaría.

	Finalmente, se presenta la relación de reducción.
	Los constructores \AgdaInductiveConstructor{$\xi$} y \AgdaInductiveConstructor{$\zeta$} representan las reglas de congruencia que permiten construir reducciones sobre sub-términos.

	\begin{codigo}
		Tipo de dato de la relación de reducción
		\input{code/reduction.tex}
	\end{codigo}
	
	Es importante destacar que el tipo de \AgdaDatatype{$\_\hookrightarrow\_$}, está indexado por dos términos del mismo tipo \AgdaBound{A}.
	Por lo tanto, no es necesario demostrar que la reducción preserva tipos, ya que es imposible construir una reducción que arribe a un término de distinto tipo.
	Esta es una de las ventajas más importante de utilizar tipos intrínsecos.
	
	% Formalizar tipos, términos y relación de reducción.
	% Las substituciones están basadas en http://strictlypositive.org/ren-sub.pdf
	% Archivos: Type, Term, Subs (sin lemas), Reduction
	
	\subsection{Isomorfismo de términos}
	
	Los isomorfismos de tipos que se incluyen en esta formalización corresponden al conjunto axiomático $Th^1_{\times\top}$.
	Además de los axiomas, se definen los constructores \AgdaInductiveConstructor{sym} y \AgdaInductiveConstructor{cong} que representan las simetrías y congruencias respectivamente.
	
	\begin{codigo}
		Tipo de dato de los isomorfismos de tipos
		\input{code/iso_type.tex}
	\end{codigo}
	
	Utilizando estos constructores es posible crear cualquier isomorfismo.
	Notar que no existe una regla para la transitividad, ya que es posible obtenerla aplicando dos veces el constructor \AgdaInductiveConstructor{$[\_]\equiv\_$}.
	Por ejemplo, el término \AgdaInductiveConstructor{[ trans} \AgdaBound{$iso_1$} \AgdaBound{$iso_2$} \AgdaInductiveConstructor{]$\equiv$} \AgdaBound{t} puede ser construido como \AgdaInductiveConstructor{[} \AgdaBound{$iso_2$} \AgdaInductiveConstructor{]$\equiv$} (\AgdaInductiveConstructor{[} \AgdaBound{$iso_1$} \AgdaInductiveConstructor{]$\equiv$} \AgdaBound{t}).
	
	A continuación se presentan los isomorfismos de términos.
	Esta selección de constructores es el resultado de varias decisiones de diseño basadas principalmente en dos objetivos.
	
	En primer lugar, se agregaron todos los isomorfismos necesarios para que ningún término quede atascado y no existan eliminaciones en formas normales, esto tiene como consecuencia que todo término cerrado reduce siempre a un valor.
	Este punto es más evidente cuando se tiene en cuenta la prueba de progreso presentada más adelante.
	
	El segundo objetivo es preservar la propiedad de normalización y evitar que su prueba se torne demasiado compleja.
	Una consecuencia directa de esto son los constructores con el prefijo \AgdaInductiveConstructor{sym-}, todos estos se podrían obtener a partir de los isomorfismos base combinados con un constructor \AgdaInductiveConstructor{sym} tal y como se construyen los isomorfismos de tipos.
	Sin embargo, incluir el constructor \AgdaInductiveConstructor{sym} genera problemas a la hora de formalizar la prueba de normalización fuerte.
	Por otro lado, para desatascar algunos términos, es necesario incluir la $\eta$-expansión y una regla \textsc{split} $r \rightleftarrows \langle \pi_A\; r , \pi_B\; r \rangle$ donde $r: A \times B$.
	Si se incluyen estas reglas directamente, se pierde la propiedad de normalización, ya que por ejemplo nada impediría aplicar la $\eta$-expansión un número infinito de veces.
	La solución es definir nuevos constructores que embeben estas reglas, como por ejemplo \AgdaInductiveConstructor{asso-split}.
	
	
	\begin{codigo}
		Tipo de dato de los isomorfismos de términos
		\input{code/iso_term.tex}
	\end{codigo}
	
	Al igual que en la relación de reducción, los tipos intrínsecos garantizan que los términos transformados por los isomorfismos preservan sus tipos.
	Notar como todos los isomorfismos base presentan una regla ($\equiv$) del lado izquierdo, la cual desaparece del lado derecho.
	Por lo tanto, los isomorfismos solo pueden aplicarse para eliminar un constructor ($\equiv$) del término.
	Este último punto es fundamental para preservar la propiedad de normalización.
	
	% Explicar los isos nuevos que voy a agregar. Formalizar iso tipos y relación de iso.
	% Archivos: IsoType, IsoTerm
	
	\subsection{Preservación de tipos}
	
	Es importante destacar que la representación con tipos intrínsecos provee implícitamente la propiedad de preservación.
	Tanto los isomorfismos de términos como la relación de reducción, y por lo tanto, la substitución, solo relacionan términos del mismo tipo.
	En consecuencia, no puede darse el caso en el que un término reduzca, de forma errónea, a otro de un tipo distinto.
	

	\section{Progreso}
	
	\subsection{Formas normales, neutrales y valores}
	
	La propiedad de progreso dice que todo término puede o bien dar un paso de reducción, o bien se encuentra en un estado final.
	Si solo se consideran términos cerrados, es decir, que no contienen variables libres, los estados finales son los valores.
	Existen tres constructores para los valores, estos son, los pares de valores, las abstracciones y el término $\star$.
	
	\begin{codigo}
		Tipo de dato de los valores
		\ExecuteMetaData[code/progress.tex]{value}
	\end{codigo}
	
	Sin embargo, en este caso, se implementa el orden de reducción aplicativo, por lo tanto, se deben reducir los cuerpos de las abstracciones.
	Cuando se reduce debajo de las abstracciones es posible encontrar variables libres, por este motivo los estados finales que se deben considerar son formas normales.
	
	Se dice que un término se encuentra en forma normal cuando no puede ser reducido, en este caso, los cuatro constructores son, un par de términos en forma normal, una abstracción donde el cuerpo está en forma normal, el término $\star$, o una forma neutral.
	
	Se dice que un término está en forma neutral cuando no puede ser reducido y no es un valor, es decir, puede ser una variable, una proyección donde el cuerpo es neutral, o una aplicación donde la función es neutral y el argumento está en forma normal.
	
	\begin{codigo}
		Caracterización inductiva de las formas normales y neutrales
		\ExecuteMetaData[code/progress.tex]{normal}
	\end{codigo}
	
	Notar como las definiciones de \AgdaInductiveConstructor{$\Uparrow$} y \AgdaInductiveConstructor{$\Downarrow$} son mutuamente recursivas.
	
	Se puede observar que en la definición de las formas neutrales, el único constructor que no es recursivo es el de las variables.
	Para poder construir una forma neutral, necesariamente se debe utilizar el caso base de la variable al menos una vez.
	Por lo tanto, un término está en forma neutral si y solo si contiene variables libres.
	Luego, es fácil ver que todo término cerrado en forma normal es un valor.
	
	\begin{codigo}
		Todo término cerrado en forma normal es un valor
		\ExecuteMetaData[code/progress.tex]{proof}
	\end{codigo}
	
	\subsection{Estrategia de reducción}
	
	La formalización de progreso implementa una estrategia de reducción \textit{strong call-by-value}, es decir, reduce primero los argumentos de las aplicaciones antes de aplicar la $\beta$-reducción, y además, reduce debajo de los lambdas.
	
	Se define un nuevo tipo de datos \AgdaDatatype{Progress}, que representa los tres posibles resultados de aplicar la prueba de progreso sobre un término, estos son, dar un paso de reducción $\hookrightarrow$, aplicar un isomorfismo $\rightleftarrows$, o puede encontrarse en forma normal, en cuyo caso no es posible seguir reduciéndolo.
	
	\begin{codigo}
		Propiedad de progreso
		\ExecuteMetaData[code/progress.tex]{progress}
	\end{codigo}
	
	La definición de \AgdaFunction{progress} muestra claramente como cada isomorfismo de término se corresponde con un caso donde es necesario eliminar una regla $(\equiv)$ para poder continuar con la reducción.
	En la formalización, el lenguaje es dirigido por sintaxis.
	Cuando se representan los términos usando tipos intrínsecos, la sintaxis del lenguaje contiene los isomorfismos de tipos.
	Por lo tanto, tiene sentido que los isomorfismos de términos también sean dirigidos por sintaxis.
	% TODO: ver si esto tiene sentido
	
	Otra observación interesante es que gracias al paradigma de proposiciones como tipos, la prueba de la propiedad de progreso es también un programa que puede ser aplicado sobre un término para obtener el siguiente paso de reducción.
	
	\section{Evaluación}
	
	A través de la aplicación sucesiva de la prueba de progreso se puede definir la evaluación.
	Para esto, se define la relación \AgdaDatatype{$\_\rightsquigarrow\_$}, que representa la clausura reflexiva y transitiva de la unión entre las relaciones \AgdaDatatype{$\_\hookrightarrow\_$} y \AgdaDatatype{$\_\rightleftarrows\_$}.
	
	\begin{codigo}
		Relación de reducción
		\ExecuteMetaData[code/eval.tex]{relation}
	\end{codigo}
	
	La evaluación se define sobre términos cerrados, de modo que estos siempre reduzcan a un valor.
	La definición aplica la prueba de progreso para obtener el nuevo término sobre el cual hacer el llamado recursivo y el paso de reducción que extenderá la relación \AgdaDatatype{$\_\rightsquigarrow\_$}.
	
	Debido a que el llamado recursivo se hace sobre el término resultante luego de un paso, Agda no tiene forma de determinar que dicho término es estructuralmente más pequeño que el argumento inicial.
	De hecho, probar la terminación de la evaluación, implicaría que todo término reduce a un valor en una cantidad finita de pasos, es decir, se estaría probando la propiedad de normalización.
	La prueba de dicha propiedad no es trivial, y se presentará en los siguientes capítulos.
	
	Por este motivo, es necesario añadir un argumento de tipo \AgdaDatatype{$\mathbb{N}$} para que la definición sea aceptada por el chequeo de terminación de Agda.
	De este modo, la evaluación realizará a lo sumo $n$ llamadas recursivas.
	Además, se utiliza \AgdaDatatype{Maybe} en el tipo de retorno, en caso de que el término no converja a un valor luego de $n$ pasos, simplemente se retorna \AgdaInductiveConstructor{nothing}.

	
	\begin{codigo}
		Evaluación
		\ExecuteMetaData[code/eval.tex]{eval}
	\end{codigo}
	
	%Ver si esta bien llama reducción a $\hookrightarrow$ o a $\rightsquigarrow$
	%Archivos: Progress, Eval (sin SN)
	
	\section{Normalización Fuerte}
	
	La propiedad de normalización fuerte dice que para cualquier término dado, toda secuencia de reducción eventualmente concluye, sin importar el camino elegido.
	O dicho de otra forma, no es posible construir secuencias de reducción infinitas.
	Se puede codificar esta propiedad definiendo un tipo de datos que predique sobre los términos del lenguaje.
	
	\begin{codigo}
		Propiedad de normalización fuerte
		\ExecuteMetaData[code/strong_norm.tex]{SN}
	\end{codigo}
	
	Notar que es trivial construir un término de tipo \AgdaDatatype{SN} para un término en forma normal, ya que, al no existir ninguna reducción posible para dicho tipo, simplemente se debe pasar la función vacía como argumento a \AgdaInductiveConstructor{sn}.
	Estos representan los casos bases del tipo \AgdaDatatype{SN}.
	%TODO: Mostrar ejemplo
	
	El hecho de que exista un término de tipo \AgdaDatatype{SN} \AgdaBound{t} implica que no existen secuencias de reducción infinitas a partir de \AgdaBound{t}, de otro modo, no hubiera sido posible construir dicho término.
	El objetivo final de esta sección será entonces, definir una función que dato un término cualquiera, permite obtener un término de tipo \AgdaDatatype{SN} \AgdaBound{t}:
	
	\AgdaFunction{strong-norm}\AgdaSpace{}%
	\AgdaSymbol{:}\AgdaSpace{}%
	\AgdaSymbol{∀}\AgdaSpace{}%
	\AgdaSymbol{\{}\AgdaBound{Γ}\AgdaSpace{}%
	\AgdaBound{A}\AgdaSymbol{\}}\AgdaSpace{}%
	\AgdaSymbol{(}\AgdaBound{t}\AgdaSpace{}%
	\AgdaSymbol{:}\AgdaSpace{}%
	\AgdaBound{Γ}\AgdaSpace{}%
	\AgdaOperator{\AgdaDatatype{⊢}}\AgdaSpace{}%
	\AgdaBound{A}\AgdaSymbol{)}\AgdaSpace{}%
	\AgdaSymbol{→}\AgdaSpace{}%
	\AgdaDatatype{SN}\AgdaSpace{}%
	\AgdaBound{t}
	
	La prueba aquí presentada está basada y extendida a partir de una formalización realiza por 
	Andras Kovacs\footnote{\citeurl{Kovacs}} para cálculo lambda simplemente tipado.
	A su vez, el trabajo de Kovacs se basa en la tesis de Steven Schäfer\cite{Schafer}, donde se formaliza la prueba de normalización fuerte para Sistema-F en Coq.
	La técnica utilizada por Schäfer difiere en ciertos aspectos con la prueba de candidatos de reducibilidad de Girard\cite{Girard}.
	Además, se utilizó como referencia una formalización de candidatos de reducibilidad en Agda realizada por Pablo Barenbaum\footnote{\citeurl{Barenbaum}}.
	
	\subsection{Prueba para STLC con pares y Top}
	
	Con el objetivo de facilitar la comprensión de la prueba, la misma será presentada en dos partes.
	En esta sección se explicará la prueba para cálculo lambda simplemente tipado con pares, es decir, sin incluir la relación de isomorfismos entre términos.
	Y en la siguiente sección se presentarán los cambios necesarios para extender la prueba a Sistema-I.
	
	
	Por lo tanto, se define el predicado \AgdaDatatype{SN} utilizando solo la relación \AgdaDatatype{$\_\hookrightarrow\_$}

	\ExecuteMetaData[code/strong_norm_base.tex]{sn}
	
	La idea de la prueba es definir una generalización del tipo \AgdaDatatype{SN} que añade un predicado sobre el término $t$.
	
	\ExecuteMetaData[code/strong_norm_base.tex]{sn-star}
	
	Luego, se define lo que se denomina conjunto adecuado.
	%TODO: ver si este nombre está bien
	
	\ExecuteMetaData[code/strong_norm_base.tex]{candidate}
	
	Es fácil ver que si un término cumple con el predicado \AgdaDatatype{SN*} también cumple con \AgdaDatatype{SN}
	
	\ExecuteMetaData[code/strong_norm_base.tex]{sn-star-sn}
	
	La definición de los conjuntos adecuados se extiende a las substituciones.
	Una substitución es adecuada cuando todos los términos por los cuales substituye las variables, cumple con el predicado \AgdaDatatype{SN*}
	
	\ExecuteMetaData[code/strong_norm_base.tex]{adecuacy-subst}
	
	En particular, la substitución identidad \AgdaFunction{ids} es una substitución adecuada
	\ExecuteMetaData[code/strong_norm_base.tex]{adecuacy-ids}
	
	Toda la complejidad de la prueba se centra en probar el teorema fundamental, el cual implica que para todo término $t$ y substitución $\sigma$ se cumple \AgdaDatatype{SN*}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{⟦\AgdaUnderscore{}⟧}}\AgdaSpace{}%
	\AgdaSymbol{(}\AgdaOperator{\AgdaFunction{⟪}}\AgdaSpace{}%
	\AgdaBound{σ}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{⟫}}\AgdaSpace{}%
	\AgdaBound{t}\AgdaSymbol{)}
	
	\ExecuteMetaData[code/strong_norm_base.tex]{adecuacy-type}
	
	\newcommand{\snstar}{\AgdaDatatype{SN*}\AgdaSpace{}\AgdaOperator{\AgdaFunction{⟦\AgdaUnderscore{}⟧}\AgdaSpace{}}}
	\newcommand{\cand}[1]{\AgdaOperator{\AgdaFunction{⟦}}\AgdaSpace{}#1\AgdaSpace{}\AgdaOperator{\AgdaFunction{⟧}}}

	\paragraph{Caso variable}
	
	Este caso requiere que la substitución $\sigma$ aplicada a la variable $v$ cumpla con la propiedad
	\snstar.
	La hipótesis dice que $\sigma$ es una substitución adecuada, por lo tanto, basta con simplemente aplicar dicha hipótesis a la variable $v$.
	
	\ExecuteMetaData[code/strong_norm_base.tex]{adecuacy-var}

	\paragraph{Caso top}
	
	Debido a que no existe ningún paso de reducción posible para el término \AgdaInductiveConstructor{$\star$}, la construcción del predicado es trivial.
	
	\ExecuteMetaData[code/strong_norm_base.tex]{lemma-top}
	\ExecuteMetaData[code/strong_norm_base.tex]{adecuacy-top}

	\paragraph{Caso producto}
	
	Para el caso del producto, se puede definir un lema que permite construir el predicado si se tiene como hipótesis que \snstar vale para los sub-términos $a$ y $b$ del par.
	Estas dos hipótesis son necesarias para obtener \snstar \AgdaBound{a'} y \snstar \AgdaBound{b'} a partir de cada uno de los dos pasos de reducción de congruencia.
	
	\ExecuteMetaData[code/strong_norm_base.tex]{lemma-prod}
	
	Luego, se utiliza la hipótesis inductiva en \AgdaFunction{adecuacy} sobre $a$ y $b$ para instanciar el lema
	
	\ExecuteMetaData[code/strong_norm_base.tex]{adecuacy-pair}
	
	\paragraph{Caso proyección}
	
	El caso de la proyección también requiere como hipótesis que se cumpla el predicado para el término que se está proyectando.
	Los pasos de reducción \AgdaInductiveConstructor{β-π₁} y \AgdaInductiveConstructor{β-π₂} implican que $t$ tiene forma $\langle a, b \rangle$, estos requieren obtener \snstar \AgdaBound{a} y \snstar \AgdaBound{b} respectivamente.
	El problema es que no se puede concluir nada sobre $a$ y $b$ a partir de \AgdaBound{SNt}.
	Aquí se vuelve evidente porque es necesario generalizar la propiedad \AgdaDatatype{SN} y añadir los conjuntos adecuados.
	Para un par $\langle a, b \rangle$ el conjunto adecuado tiene forma
	\snstar\AgdaBound{a} \AgdaOperator{\AgdaFunction{⊗}} \snstar\AgdaBound{b}
	esto es precisamente lo que necesitamos probar en ambos casos.

	\ExecuteMetaData[code/strong_norm_base.tex]{lemma-proj}
	\ExecuteMetaData[code/strong_norm_base.tex]{adecuacy-proj}
	
	\paragraph{Caso aplicación}
	
	Este caso es similar al producto, ya que la hipótesis del lema requiere que el predicado se cumpla para ambos sub-términos.
	Por otro lado, la solución para el caso de la $\beta$-reducción es similar al caso de la proyección, puesto que se utiliza el conjunto adecuado.
	Para el constructor \AgdaInductiveConstructor{β-ƛ}, el término $a$ es de la forma $\lambda\; t$, por lo que se debe obtener
	\snstar(\AgdaBound{t}\AgdaFunction{[}\AgdaBound{b}\AgdaFunction{]}).
	El conjunto adecuado 
	\AgdaOperator{\AgdaFunction{⟦}}\AgdaBound{a}\AgdaOperator{\AgdaFunction{⟧}}
	será de la forma
	\snstar\AgdaBound{u}\AgdaSpace{}%
	\AgdaSymbol{→}\AgdaSpace{}%
	\snstar
	\AgdaSymbol{(}\AgdaOperator{\AgdaFunction{⟪}}\AgdaSpace{}%
	\AgdaBound{u}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{•}}\AgdaSpace{}%
	\AgdaSymbol{(}\AgdaFunction{ids}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{∘}}\AgdaSpace{}%
	\AgdaBound{ρ}\AgdaSymbol{)}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{⟫}}\AgdaSpace{}%
	\AgdaBound{t}\AgdaSymbol{)}
	es decir que basta con aplicar dicha función a \AgdaBound{SN*b}
	
	\ExecuteMetaData[code/strong_norm_base.tex]{lemma-app}
	\ExecuteMetaData[code/strong_norm_base.tex]{adecuacy-app}
	
	Notar como los conjuntos adecuados permiten resolver los casos de la proyección y aplicación, pero, por otro lado, los casos del producto y la abstracción se vuelven más complejos, ya que son estos los que construyen dichos conjuntos adecuados.
	Esta construcción es simple para los productos, puesto que se puede deducir de forma directa aplicando la hipótesis inductiva en \AgdaFunction{adecuacy}.	
	Sin embargo, como se verá más adelante, obtener el conjunto adecuado correspondiente al caso de las abstracciones, resulta particularmente complejo.
	
	\paragraph{Caso isomorfismo}
	
	Este caso no presenta mayores dificultades. Sin embargo, la mayor parte de la complejidad para la extensión de la prueba a Sistema I, se presentará cuando se añadan todos los constructores de isomorfismos de términos a este lema.
	
	\ExecuteMetaData[code/strong_norm_base.tex]{lemma-iso}
	\ExecuteMetaData[code/strong_norm_base.tex]{adecuacy-iso}
	
	\paragraph{Caso abstracción}
	
	La prueba del lema para el caso de la abstracción requiere obtener el conjunto adecuado  \AgdaOperator{\AgdaFunction{⟦}}\AgdaSpace{}%
	\AgdaOperator{\AgdaInductiveConstructor{ƛ}}\AgdaSpace{}%
	\AgdaBound{t'}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{⟧}}\AgdaSpace{}%
	en la llamada inductiva.
	Para ello es necesario definir un nuevo lema que permite conjugar un paso de reducción con cualquier substitución.
	
	\ExecuteMetaData[code/strong_norm_base.tex]{reduction-subst}
	
	Luego se utiliza la hipótesis \AgdaBound{Lƛ} en conjunto un nuevo lema.
	
	\ExecuteMetaData[code/strong_norm_base.tex]{lemma-abs}
	
	La instanciación de las hipótesis necesarias para utilizar el lema en la prueba de \AgdaFunction{adecuacy} requiere especial atención.
	
	Por un lado, para obtener la hipótesis \snstar \AgdaBound{t}, primero se debe probar que la extensión de una substitución adecuada sigue siendo adecuada.
	
	\ExecuteMetaData[code/strong_norm_base.tex]{adecuacy-exts}
	
	A su vez, para esta prueba es necesario demostrar que si se aplica un renombre de variables a un término \snstar esté no perderá dicha propiedad, esto tiene sentido, ya que los renombres no alteran el significado de los términos y, por lo tanto, preservan la propiedad \snstar
	
	\ExecuteMetaData[code/strong_norm_base.tex]{sn-rename}
	
	Aquí se deben hacer dos observaciones importantes.
	En primer lugar, el caso de la abstracción en la prueba de \AgdaFunction{⟦⟧-rename} es el único lugar donde es necesario usar el argumento $\rho$ del conjunto adecuado.
	De hecho, este es precisamente el motivo por el cual es necesario añadir un renombre en la definición del conjunto adecuado para lambdas.
	
	En segundo lugar, en la prueba de \AgdaFunction{SN*-rename} se debe eliminar el renombre del paso de reducción para poder utilizar la hipótesis \AgdaBound{SNt}.
	Para ello se define el siguiente lema:
	
	\ExecuteMetaData[code/strong_norm_base.tex]{rename-reduction-type}
	
	Básicamente, el lema dice que si una reducción parte de un término renombrado $t_\rho$, el resultado será un término $t'_\rho$, donde $t'$ se obtiene dando un paso de reducción desde $t$.
	
	
	Por otro lado, para obtener el conjunto adecuado
	\AgdaOperator{\AgdaFunction{⟦}}\AgdaSpace{}%
	\AgdaOperator{\AgdaInductiveConstructor{ƛ}}\AgdaSpace{}%
	\AgdaBound{t}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{⟧}}\AgdaSpace{}%
	se necesita demostrar dos propiedades más sobre las substituciones adecuadas.
	
	Una de ella dice que una substitución adecuada compuesta con un renombre, es también una substitución adecuada.
	La prueba utiliza el hecho de que \AgdaFunction{rename}\AgdaSpace{}\AgdaBound{ρ} puede ser escrito como
	\AgdaOperator{\AgdaFunction{⟪}}\AgdaSpace{}%
	\AgdaFunction{ids}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{∘}}\AgdaSpace{}%
	\AgdaBound{ρ}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{⟫}}\AgdaSpace{}%
	
	\ExecuteMetaData[code/strong_norm_base.tex]{adecuacy-rename}
	
	La otra propiedad, dice que el cons entre un término \snstar y una substitución adecuada, es también una substitución adecuada.
	
	\ExecuteMetaData[code/strong_norm_base.tex]{adecuacy-cons}
	
	Un último detalle a destacar es que \AgdaFunction{adecuacy} toma como argumento solo una substitución, por lo que se debe combinar \AgdaBound{$\sigma$} y
	\AgdaBound{u}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{•}}\AgdaSpace{}%
	\AgdaSymbol{(}\AgdaFunction{ids}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{∘}}\AgdaSpace{}%
	\AgdaBound{ρ}\AgdaSymbol{)}
	en una sola substitución y demostrar que aplicar dicha combinación es equivalente a aplicarlas por separado.

	\ExecuteMetaData[code/strong_norm_base.tex]{subst-split}
	
	%\ExecuteMetaData[code/strong_norm_base.tex]{subst-split-simple}
	
	\begin{samepage}
	\ExecuteMetaData[code/strong_norm_base.tex]{adecuacy-abs}
	\end{samepage}
	
	%\ExecuteMetaData[code/strong_norm_base.tex]{adecuacy}
	
	\paragraph{Cierre de la prueba}
	
	Finalmente, se prueba la propiedad de normalización fuerte instanciando \AgdaFunction{adecuacy} con la substitución identidad.
	
	Como detalle adicional, se elimina la substitución identidad aplicada al término utilizando el lema
	\AgdaFunction{sub-id}\AgdaSpace{}%
	\AgdaSymbol{:}\AgdaSpace{}%
	\AgdaSymbol{∀\{}\AgdaBound{Γ}\AgdaSpace{}%
	\AgdaBound{A}\AgdaSymbol{\}}\AgdaSpace{}%
	\AgdaSymbol{\{}\AgdaBound{N}\AgdaSpace{}%
	\AgdaSymbol{:}\AgdaSpace{}%
	\AgdaBound{Γ}\AgdaSpace{}%
	\AgdaOperator{\AgdaDatatype{⊢}}\AgdaSpace{}%
	\AgdaBound{A}\AgdaSymbol{\}}\AgdaSpace{}%
	\AgdaSymbol{→}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{⟪}}\AgdaSpace{}%
	\AgdaFunction{ids}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{⟫}}\AgdaSpace{}%
	\AgdaBound{N}\AgdaSpace{}%
	\AgdaOperator{\AgdaDatatype{≡}}\AgdaSpace{}%
	\AgdaBound{N}
	
	\ExecuteMetaData[code/strong_norm_base.tex]{strong-norm}


	\subsection{Prueba para Sistema I}
	
	El primer paso para extender la prueba, es agregar la definición de \AgdaDatatype{SN} la relación de isomorfismos entre términos.
	
	\ExecuteMetaData[code/strong_norm.tex]{SN}
	\ExecuteMetaData[code/strong_norm.tex]{sn-star}
	
	Este cambio tiene como consecuencia que todas las partes de la prueba que construían un término \snstar haciendo \textsc{pattern matching} sobre la relación $\hookrightarrow$, ahora deberán tener también en cuenta los de la relación $\rightleftarrows$ que sean aplicables en cada caso.
	
	Por ejemplo, la prueba de \AgdaFunction{SN*-rename} ahora los dos constructores \AgdaInductiveConstructor{inj₁} y \AgdaInductiveConstructor{inj₂} del tipo suma.
	
	\ExecuteMetaData[code/strong_norm.tex]{sn-rename}
	
	Para esta prueba es necesario definir un nuevo lema análogo a \AgdaFunction{rename↪}.
	
	\ExecuteMetaData[code/strong_norm.tex]{rename-iso-type}
	
	Una modificación similar se realiza para extender el lema de la abstracción.
	
	\ExecuteMetaData[code/strong_norm.tex]{lemma-abs}
	
	Este caso también requiere la definición de un nuevo lema análogo al definido para la relación $\hookrightarrow$ anteriormente.
	
	\ExecuteMetaData[code/strong_norm.tex]{iso-subst}
	
	La extensión del resto de los lemas no presentan mayor dificulta.
	A modo de ejemplo se presenta el lema correspondiente al producto, y se omiten los demás.
	
	\ExecuteMetaData[code/strong_norm.tex]{lemma-prod}
	
	El lema para el constructor de isomorfismos es donde se concentra la mayor complejidad de la prueba, ya que se deben resolver los casos de todos los isomorfismos de términos.
	Para empezar, se presentan las reglas de congruencia.
	
	\ExecuteMetaData[code/strong_norm.tex]{lemma-iso-type}
	
	Luego, el objetivo para cada constructor será obtener \snstar\AgdaBound{t'} a partir de \snstar\AgdaBound{t}, donde \AgdaBound{t} y \AgdaBound{t'} son los términos relacionados por el isomorfismo correspondiente.
	La idea de la prueba es utilizar los lemas anteriormente definidos para los distintos constructores de términos.
	
	\subsubsection{Caso comm}
	
	Por ejemplo, el isomorfismo \textsc{comm} es uno de los casos más simples que ilustra la técnica utilizada.
	Aquí simplemente basta con instanciar el lema del producto utilizando las hipótesis provistas por el conjunto adecuado de los pares.
	
	\ExecuteMetaData[code/strong_norm.tex]{iso-comm}
	
	\subsubsection{Caso asso}
	
	El caso de \textsc{asso} no tiene mayor dificultad.
	Notar como se aprovecha la naturaleza constructiva de las pruebas en Agda, combinando los lemas ya definidos hasta obtener un término del tipo esperado.
	
	\ExecuteMetaData[code/strong_norm.tex]{iso-asso}
	
	\subsubsection{Caso dist}
	
	Este caso presenta la dificultad de instanciar y construir el conjunto adecuado de la abstracción.
	Además, se presentan dos nuevos lemas que se emplearan en múltiples insomorfimos.
	En primer lugar, se define un lema que permite concluir \snstar\AgdaBound{t} a partir de \snstar \AgdaInductiveConstructor{ƛ} \AgdaBound{t}.
	La idea del lema es utilizar \AgdaBound{Lt} para obtener $\llangle\; `Z \bullet S\_ \;\rrangle\;t$, es decir, se substituye la primera variable del término por el índice cero, por lo tanto, se obtiene exactamente el mismo término.
	
	\ExecuteMetaData[code/strong_norm.tex]{lemma-sub}
	
	Este lema resulta de utilidad en los casos en los que se debe construir algo a partir del cuerpo de una abstracción.
	
	\ExecuteMetaData[code/strong_norm.tex]{iso-dist}
	
	En segundo lugar, se define un lema que se empleará para probar la propiedad del conjunto adecuado de la abstracción, en los casos donde se deba $\eta$-expandir un término.
	La clave de este lema está en notar que $\llangle\; u \bullet (ids \circ \rho) \;\rrangle\;(\text{rename S\_ } t)$ es equivalente a $\llangle\; ids \circ \rho \;\rrangle\; t$ que a su vez es equivalente a $\text{rename}\;\rho\; t$
	
	\ExecuteMetaData[code/strong_norm.tex]{lemma-S}
	
	\ExecuteMetaData[code/strong_norm.tex]{iso-distlr}
	
	\subsubsection{Caso congruencia abstracción}
	
	El siguiente caso presenta un isomorfismo donde aparece una substitución en el término de la derecha.
	Coloquialmente, la substitución \AgdaFunction{σ-cong⇒₁} reemplaza el primer índice del término por
	\AgdaOperator{\AgdaInductiveConstructor{[}}\AgdaSpace{}%
	\AgdaBound{iso}\AgdaSpace{}%
	\AgdaOperator{\AgdaInductiveConstructor{]≡}}\AgdaSpace{}%
	\AgdaSymbol{(}\AgdaOperator{\AgdaInductiveConstructor{`}}\AgdaSpace{}%
	\AgdaInductiveConstructor{Z}\AgdaSymbol{)}
	y deja el resto de los índices intactos.
	La hipótesis \AgdaBound{Lt} permite obtener un término de la forma
	\snstar
	\AgdaSymbol{(}\AgdaOperator{\AgdaFunction{⟪}}\AgdaSpace{}%
	\AgdaBound{u}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{•}}\AgdaSpace{}%
	\AgdaSymbol{(}\AgdaFunction{ids}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{∘}}\AgdaSpace{}%
	\AgdaBound{ρ}\AgdaSymbol{)}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{⟫}}\AgdaSpace{}%
	\AgdaBound{t}\AgdaSymbol{)}
	, entonces, la estrategia será hallar un renombre $\rho$ y un término $u$ que den como resultado el término esperado en cada caso.
	
	Para instanciar el lema de la abstracción, las dos hipótesis requeridas en este caso son:
	
	\snstar
	\AgdaSymbol{(}\AgdaOperator{\AgdaFunction{⟪}}\AgdaSpace{}%
	\AgdaBound{u}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{•}}\AgdaSpace{}%
	\AgdaSymbol{(}\AgdaFunction{ids}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{∘}}\AgdaSpace{}%
	\AgdaBound{ρ}\AgdaSymbol{)}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{⟫}}\AgdaSpace{}%
	\AgdaSymbol{(}\AgdaOperator{\AgdaFunction{⟪}}\AgdaSpace{}%
	\AgdaOperator{\AgdaInductiveConstructor{[}}\AgdaSpace{}%
	\AgdaBound{iso}\AgdaSpace{}%
	\AgdaOperator{\AgdaInductiveConstructor{]≡}}\AgdaSpace{}%
	\AgdaSymbol{(}\AgdaOperator{\AgdaInductiveConstructor{`}}\AgdaSpace{}%
	\AgdaInductiveConstructor{Z}\AgdaSymbol{)}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{•}}\AgdaSpace{}%
	\AgdaSymbol{(}\AgdaFunction{ids}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{∘}}\AgdaSpace{}%
	\AgdaOperator{\AgdaInductiveConstructor{S\AgdaUnderscore{}}}\AgdaSymbol{)}
	\AgdaOperator{\AgdaFunction{⟫}}\AgdaSpace{}%
	\AgdaBound{t}\AgdaSymbol{))}
	
	\snstar
	\AgdaSymbol{(}\AgdaOperator{\AgdaFunction{⟪}}\AgdaSpace{}%
	\AgdaOperator{\AgdaInductiveConstructor{[}}\AgdaSpace{}%
	\AgdaBound{iso}\AgdaSpace{}%
	\AgdaOperator{\AgdaInductiveConstructor{]≡}}\AgdaSpace{}%
	\AgdaSymbol{(}\AgdaOperator{\AgdaInductiveConstructor{`}}\AgdaSpace{}%
	\AgdaInductiveConstructor{Z}\AgdaSymbol{)}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{•}}\AgdaSpace{}%
	\AgdaSymbol{(}\AgdaFunction{ids}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{∘}}\AgdaSpace{}%
	\AgdaOperator{\AgdaInductiveConstructor{S\AgdaUnderscore{}}}\AgdaSymbol{)}
	\AgdaOperator{\AgdaFunction{⟫}}\AgdaSpace{}%
	\AgdaBound{t}\AgdaSymbol{)}
	
	La segunda es la más sencilla, ya que se puede concluir directamente a partir de \AgdaBound{Lt}.
	Por otro lado, para resolver la primera, se debe notar que es posible combinar las dos substituciones en una sola 
	\AgdaOperator{\AgdaFunction{⟪}}\AgdaSpace{}%
	\AgdaSymbol{(}\AgdaOperator{\AgdaInductiveConstructor{[}}\AgdaSpace{}%
	\AgdaBound{iso}\AgdaSpace{}%
	\AgdaOperator{\AgdaInductiveConstructor{]≡}}\AgdaSpace{}%
	\AgdaBound{u}\AgdaSymbol{)}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{•}}\AgdaSpace{}%
	\AgdaFunction{ids}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{∘}}\AgdaSpace{}%
	\AgdaBound{ρ}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{⟫}}\AgdaSpace{}%
	\AgdaBound{N}
	
	\ExecuteMetaData[code/strong_norm.tex]{iso-cong-lam1}
	
	Es importante entender como se pueden combinar múltiples substituciones en una sola, que pueda ser obtenida a través del conjunto adecuado de la abstracción.
	Esta técnica será la clave para resolver los constructores correspondientes al isomorfismo \textsc{curry}, los cuales también presentan substituciones.
	
	\subsubsection{Caso curry}
	
	La estrategia para los dos constructores correspondientes a este isomorfismo será, en primer lugar, definir un lema que pruebe la primera hipótesis de \AgdaFunction{lemma-ƛ}, y luego aprovechar el hecho de que
	\AgdaOperator{\AgdaFunction{⟪}}\AgdaSpace{}%
	\AgdaOperator{\AgdaInductiveConstructor{`}}\AgdaSpace{}%
	\AgdaInductiveConstructor{Z}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{•}}\AgdaSpace{}%
	\AgdaFunction{ids}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{∘}}\AgdaSpace{}%
	\AgdaOperator{\AgdaInductiveConstructor{S\AgdaUnderscore{}}}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{⟫}}\AgdaSpace{}%
	\AgdaBound{N}\AgdaSpace{}%
	\AgdaOperator{\AgdaDatatype{≡}}\AgdaSpace{}%
	\AgdaBound{N}
	para concluir la segunda hipótesis.
	
	El constructor \AgdaInductiveConstructor{curry} tiene la particularidad de que el conjunto adecuado de su hipótesis tiene la forma 
	\AgdaOperator{\AgdaFunction{⟦}}\AgdaSpace{}%
	\AgdaOperator{\AgdaInductiveConstructor{ƛ}}\AgdaSpace{}%
	\AgdaOperator{\AgdaInductiveConstructor{ƛ}}\AgdaSpace{}%
	\AgdaBound{t}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{⟧}}\AgdaSpace{}%
	, por lo tanto, instanciandolo una vez se puede obtener un segundo conjunto de la forma
	\AgdaOperator{\AgdaFunction{⟦}}\AgdaSpace{}%
	\AgdaOperator{\AgdaInductiveConstructor{ƛ}}\AgdaSpace{}%
	\AgdaSymbol{(}\AgdaOperator{\AgdaFunction{⟪}}\AgdaSpace{}%
	\AgdaFunction{exts}
	\AgdaSymbol{(}\AgdaBound{u}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{•}}\AgdaSpace{}%
	\AgdaSymbol{(}\AgdaFunction{ids}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{∘}}\AgdaSpace{}%
	\AgdaBound{ρ}\AgdaSymbol{))}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{⟫}}\AgdaSpace{}%
	\AgdaBound{t}\AgdaSymbol{)}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{⟧}}\AgdaSpace{}%
	el cual puede ser nuevamente instanciado para obtener
	\AgdaOperator{\AgdaFunction{⟪}}\AgdaSpace{}%
	\AgdaBound{u₁}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{•}}\AgdaSpace{}%
	\AgdaSymbol{(}\AgdaFunction{ids}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{∘}}\AgdaSpace{}%
	\AgdaBound{ρ₁}\AgdaSymbol{)}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{⟫}}
	\AgdaSymbol{(}\AgdaOperator{\AgdaFunction{⟪}}\AgdaSpace{}%
	\AgdaFunction{exts}
	\AgdaSymbol{(}\AgdaBound{u}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{•}}\AgdaSpace{}%
	\AgdaSymbol{(}\AgdaFunction{ids}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{∘}}\AgdaSpace{}%
	\AgdaBound{ρ}\AgdaSymbol{))}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{⟫}}\AgdaSpace{}%
	\AgdaBound{t}\AgdaSymbol{)}
	
	Por otro lado, se debe notar que es posible reescribir el objetivo del lema de una forma equivalente
	\AgdaOperator{\AgdaFunction{⟪}}\AgdaSpace{}%
	\AgdaInductiveConstructor{π}\AgdaSpace{}%
	\AgdaBound{B}\AgdaSpace{}%
	\AgdaSymbol{\{}\AgdaInductiveConstructor{inj₂}\AgdaSpace{}%
	\AgdaInductiveConstructor{refl}\AgdaSymbol{\}}\AgdaSpace{}%
	\AgdaBound{u}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{•}}\AgdaSpace{}%
	\AgdaFunction{ids}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{⟫}}\AgdaSpace{}%
	\AgdaSymbol{(}\AgdaOperator{\AgdaFunction{⟪}}\AgdaSpace{}%
	\AgdaFunction{exts}\AgdaSpace{}%
	\AgdaSymbol{(}\AgdaInductiveConstructor{π}\AgdaSpace{}%
	\AgdaBound{A}\AgdaSpace{}%
	\AgdaSymbol{\{}\AgdaInductiveConstructor{inj₁}\AgdaSpace{}%
	\AgdaInductiveConstructor{refl}\AgdaSymbol{\}}\AgdaSpace{}%
	\AgdaBound{u}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{•}}\AgdaSpace{}%
	\AgdaFunction{ids}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{∘}}\AgdaSpace{}%
	\AgdaBound{ρ}\AgdaSymbol{)}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{⟫}}\AgdaSpace{}%
	\AgdaBound{t}\AgdaSymbol{)}
	. Es posible obtener esta forma utilizando los conjuntos adecuados.
	
	\ExecuteMetaData[code/strong_norm.tex]{lemma-curry}
	\ExecuteMetaData[code/strong_norm.tex]{iso-curry}
	
	Para el caso \AgdaInductiveConstructor{uncurry} se debe realizar, en cierta forma, un razonamiento opuesto.
	Si en el caso anterior se utilizaron dos hipótesis anidadas para instanciar un solo \AgdaFunction{lemma-ƛ}, en este caso se utilizará una sola hipótesis para instanciar dos \AgdaFunction{lemma-ƛ} anidados.
	
	El primer lema requiere obtener
	\AgdaOperator{\AgdaFunction{⟪}}\AgdaSpace{}%
	\AgdaFunction{exts}\AgdaSpace{}%
	\AgdaSymbol{(}\AgdaBound{u}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{•}}\AgdaSpace{}%
	\AgdaFunction{ids}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{∘}}\AgdaSpace{}%
	\AgdaBound{ρ}\AgdaSymbol{)}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{⟫}}\AgdaSpace{}%
	\AgdaSymbol{(}\AgdaOperator{\AgdaFunction{⟪}}\AgdaSpace{}%
	\AgdaFunction{σ-uncurry}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{⟫}}\AgdaSpace{}%
	\AgdaBound{t}\AgdaSymbol{))}
	mientras que el lema anidado requiere
	\AgdaOperator{\AgdaFunction{⟪}}\AgdaSpace{}%
	\AgdaBound{u₂}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{•}}\AgdaSpace{}%
	\AgdaFunction{ids}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{∘}}\AgdaSpace{}%
	\AgdaBound{ρ₂}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{⟫}}\AgdaSpace{}%
	\AgdaSymbol{(}\AgdaOperator{\AgdaFunction{⟪}}\AgdaSpace{}%
	\AgdaFunction{exts}\AgdaSpace{}%
	\AgdaSymbol{(}\AgdaBound{u}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{•}}\AgdaSpace{}%
	\AgdaFunction{ids}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{∘}}\AgdaSpace{}%
	\AgdaBound{ρ}\AgdaSymbol{)}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{⟫}}\AgdaSpace{}%
	\AgdaSymbol{(}\AgdaOperator{\AgdaFunction{⟪}}\AgdaSpace{}%
	\AgdaFunction{σ-uncurry}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{⟫}}\AgdaSpace{}%
	\AgdaBound{t}\AgdaSymbol{))}
	
	. Aquí es donde se debe hallar una substitución equivalente que pueda ser obtenida a través del conjunto adecuado de la abstracción.
	Notar que la primera substitución aplicada es extendida, por lo que primero se reemplaza el segundo índice por el término $u$.
	Luego, se substituye el primer índice por el término $u_1$ y se aplica el renombre $\rho_1$, por lo que $u$ será renombrado.
	Por lo tanto, la substitución equivalente es
	\AgdaOperator{\AgdaFunction{⟪}}\AgdaSpace{}%
	\AgdaOperator{\AgdaInductiveConstructor{⟨}}\AgdaSpace{}%
	\AgdaFunction{rename}\AgdaSpace{}%
	\AgdaBound{ρ₁}\AgdaSpace{}%
	\AgdaBound{u}\AgdaSpace{}%
	\AgdaOperator{\AgdaInductiveConstructor{,}}\AgdaSpace{}%
	\AgdaBound{u₁}\AgdaSpace{}%
	\AgdaOperator{\AgdaInductiveConstructor{⟩}}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{•}}\AgdaSpace{}%
	\AgdaFunction{ids}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{∘}}\AgdaSpace{}%
	\AgdaBound{ρ₁}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{∘}}\AgdaSpace{}%
	\AgdaBound{ρ}\AgdaSpace{}%
	\AgdaOperator{\AgdaFunction{⟫}}\AgdaSpace{}%
	\AgdaBound{t}
	
	\ExecuteMetaData[code/strong_norm.tex]{lemma-uncurry}
	\ExecuteMetaData[code/strong_norm.tex]{iso-uncurry}
	
	\subsubsection{Resto de casos}

	%\ExecuteMetaData[code/strong_norm.tex]{iso-sym-dist}
	\ExecuteMetaData[code/strong_norm.tex]{iso-id-prod}
	\ExecuteMetaData[code/strong_norm.tex]{iso-id-lam}
	\ExecuteMetaData[code/strong_norm.tex]{iso-abs}
	\ExecuteMetaData[code/strong_norm.tex]{iso-sym}
	
	\ExecuteMetaData[code/strong_norm.tex]{iso-cong-prod1}
	\ExecuteMetaData[code/strong_norm.tex]{iso-cong-prod2}
	
	\ExecuteMetaData[code/strong_norm.tex]{iso-cong-lam2}
	
	\subsection{Observaciones}
	% Capitulo 5.6 como referencia
	% https://www.ps.uni-saarland.de/~schaefer/thesis/draft-screen.pdf
	
	\subsection{Relación bien fundada}
	
	Una vez demostrada la propiedad de normalización fuerte, se puede definir la función de evaluación sin necesidad de utilizar un argumento extra para eludir el chequeo de terminación de Agda.
	
	\begin{codigo}
		Evaluación de un término
		\ExecuteMetaData[code/eval.tex]{eval2}
	\end{codigo}
	
	Notar que ya no aparece \AgdaDatatype{Maybe} en el tipo de retorno, puesto que se ha probado que toda reducción eventualmente concluye.
	Aquí la llamada recursiva elimina un constructor \AgdaInductiveConstructor{sn} del segundo argumento, por lo tanto, dicho argumento se hace más y más pequeño.
	De esta forma, Agda puede garantizar que la función alcanzará un caso base y la recursión concluirá.
	
	La forma en la que se codifica la propiedad de normalización fuerte y el hecho de que esta propiedad es la que nos permite realizar inducción sobre $\rightsquigarrow$ no es casualidad.
	Para entender los fundamentos que se esconden detrás de estas observaciones se presentan las siguientes definiciones.
	
	En teoría del orden, se dice que una relación es bien fundada cuando todas sus cadenas, de la forma $x_1 < x_2 < \dots < x_n$, tienen un largo acotado.
	Esta propiedad se denomina accesibilidad de un elemento.
	
	\begin{codigo}
		Accesibilidad de un término $x$ en la relación $\_<\_$
		\ExecuteMetaData[code/eval.tex]{acc}
	\end{codigo}
	
	Un elemento $x: A$ es accesible, si todo elemento $y < x$ es también accesible.
	Luego, una relación es bien fundada si todo elemento es accesible.
	
	\begin{codigo}
		Relación bien fundada
		\ExecuteMetaData[code/eval.tex]{wf}
	\end{codigo}
	
	Si una relación está bien fundada implica que esta soporta inducción, y en el contexto de los sistemas de reescritura, cumple con la propiedad de terminación.
	De hecho, la propiedad de normalización fuerte implica que la relación de reducción está bien fundada, y por lo tanto, soporta inducción.
	Se puede demostrar de forma sencilla esta equivalencia.

	\begin{codigo}
		La propiedad de normalización fuerte permite concluir que la relación $\rightsquigarrow$ es bien fundada
		\ExecuteMetaData[code/eval.tex]{wf-reduction}
	\end{codigo}
	
	\chapter{Conclusiones}
	% Como se resuelve la no-terminacion
	% La prueba tambien sirve para STLC
	
	\section{Trabajo futuro}
	\subsection{Inferencia de tipos}
	\subsection{Formalizar SIP}
	
	
	\printbibliography
	
\end{document}


